{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd46f10d-891a-4162-99be-1b381498457a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.9.2)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (0.26.2)\n",
      "Requirement already satisfied: jaxtyping in /usr/local/lib/python3.10/dist-packages (0.2.36)\n",
      "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (8.4.0)\n",
      "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (0.1.6)\n",
      "Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
      "Requirement already satisfied: gguf in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.12.2)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing) (0.16)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2022.12.7)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/EleutherAI/sae.git\n",
      "  Cloning https://github.com/EleutherAI/sae.git to /tmp/pip-req-build-d2_s5jbf\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/EleutherAI/sae.git /tmp/pip-req-build-d2_s5jbf\n",
      "  Resolved https://github.com/EleutherAI/sae.git to commit 3ce54b0577faf3a278a87250488cdd93271548cc\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from sae==0.1.0) (1.1.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from sae==0.1.0) (3.1.0)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from sae==0.1.0) (0.8.0)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from sae==0.1.0) (0.26.2)\n",
      "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from sae==0.1.0) (8.4.0)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from sae==0.1.0) (0.4.5)\n",
      "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from sae==0.1.0) (0.1.6)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from sae==0.1.0) (2.1.0+cu118)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from sae==0.1.0) (4.46.3)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate->sae==0.1.0) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->sae==0.1.0) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->sae==0.1.0) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate->sae==0.1.0) (6.0.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->sae==0.1.0) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->sae==0.1.0) (2024.9.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->sae==0.1.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->sae==0.1.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->sae==0.1.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->sae==0.1.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->sae==0.1.0) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->sae==0.1.0) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->sae==0.1.0) (2.1.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->sae==0.1.0) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->sae==0.1.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->sae==0.1.0) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->sae==0.1.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->sae==0.1.0) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->sae==0.1.0) (3.11.7)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->sae==0.1.0) (0.16)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->sae==0.1.0) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->sae==0.1.0) (0.20.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->sae==0.1.0) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->sae==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->sae==0.1.0) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->sae==0.1.0) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->sae==0.1.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->sae==0.1.0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->sae==0.1.0) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->sae==0.1.0) (1.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->sae==0.1.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->sae==0.1.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->sae==0.1.0) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->sae==0.1.0) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->sae==0.1.0) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->sae==0.1.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->sae==0.1.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->sae==0.1.0) (2024.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->sae==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->sae==0.1.0) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Notebook / Runpod setup, safe to ignore\n",
    "%pip install matplotlib accelerate datasets einops huggingface-hub jaxtyping natsort simple-parsing triton transformers gguf sentencepiece scikit-learn seaborn\n",
    "%pip install -U safetensors>=0.4.3\n",
    "%pip install git+https://github.com/EleutherAI/sae.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0074cbe-195f-43f3-94dd-2a049d99bbbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec2cea5e-f73c-4c67-a3e1-89305878adae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, \"/workspace/experiments\")\n",
    "os.environ[\"HF_HOME\"] = \"/workspace/experiments/hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "676136dc-cd1e-4448-941c-8dd0e5237f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "082c09924071488fbf14b32912614143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be85a3ae-6c14-43b1-8fe2-a98ba9cb0e8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from repeng import ControlVector, ControlModel, DatasetEntry\n",
    "import repeng.saes\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from collections import Counter\n",
    "import math\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fc143c3-73d3-43bb-8db1-ef201e06a944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0135b64365a4f91b26bbc5500e246be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1053539a2ef4ce3beb2d3d1f5b27ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Collect garbage\n",
    "gc.collect()\n",
    "\n",
    "# Force CUDA to sync\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "control_layers = list(range(2, 30))\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Meta-Llama-3-8B\",\n",
    "    torch_dtype=\"auto\").to(\n",
    "    torch.device(\"cuda:0\"))\n",
    "base_model = ControlModel(base_model, control_layers)\n",
    "\n",
    "instruct_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    torch_dtype=\"auto\").to(\n",
    "    torch.device(\"cuda:0\"))\n",
    "instruct_model = ControlModel(instruct_model, control_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbe04ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff73472db39418aa48f531637ad0494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 66 files:   0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:11<00:00,  2.54it/s]\n"
     ]
    }
   ],
   "source": [
    "sae = repeng.saes.from_eleuther(device=\"cuda:0\", layers=control_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d51f538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4998731cd64175aed830925d2d456d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Text Generation Demo</h3>'), ToggleButtons(options=('Base Mode', 'Chat Mode'), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import textwrap\n",
    "\n",
    "with open(\"/workspace/experiments/notebooks/data/all_truncated_outputs.json\") as f:\n",
    "    output_suffixes = json.load(f)\n",
    "truncated_output_suffixes = [\n",
    "    tokenizer.convert_tokens_to_string(tokens[:i])\n",
    "    for tokens in (tokenizer.tokenize(s) for s in output_suffixes)\n",
    "    for i in range(1, len(tokens))\n",
    "]\n",
    "\n",
    "def visualize_discontinuities(x, y, discontinuities):\n",
    "    \"\"\"\n",
    "    Visualize the detected discontinuities on the original data.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # Change from line plot to scatter plot\n",
    "    plt.scatter(x, y, c='b', s=20, alpha=0.6, label='Original data')\n",
    "    \n",
    "    x_discontinuities = x[discontinuities]\n",
    "    y_discontinuities = y[discontinuities]\n",
    "\n",
    "    plt.scatter(x_discontinuities, y_discontinuities, c='r', s=100, \n",
    "               label='Detected discontinuities', zorder=3)\n",
    "    \n",
    "    # Add vertical lines at discontinuities\n",
    "    for idx in discontinuities:\n",
    "        plt.axvline(x=x[idx], color='r', linestyle='--', alpha=0.3)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.title('Detected Discontinuities')\n",
    "    plt.show()\n",
    "\n",
    "def find_significant_drop(x, y, drop_threshold=0.2, window_size=1):\n",
    "    \"\"\"\n",
    "    Find the first point where perplexity drops significantly below starting value.\n",
    "    \n",
    "    Parameters:\n",
    "    x: array-like, coefficients\n",
    "    y: array-like, perplexity values\n",
    "    drop_threshold: float, minimum drop as fraction of starting value (default 0.2 = 20%)\n",
    "    window_size: int, number of consecutive points to check to avoid noise (default 3)\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (x value where drop occurs, index of drop point)\n",
    "    \"\"\"\n",
    "    # Get baseline from start of sequence\n",
    "    baseline = y[0]\n",
    "    target_value = baseline * (1 - drop_threshold)\n",
    "    \n",
    "    # Look for first window where all values are below target\n",
    "    for i in range(len(y) - window_size + 1):\n",
    "        window = y[i:i+window_size]\n",
    "        if all([val < target_value for val in window]):\n",
    "            return i\n",
    "            \n",
    "    # If no significant drop found\n",
    "    return None\n",
    "\n",
    "\n",
    "def calculate_sequence_probability(model, sequence):\n",
    "    input_ids = sequence.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "    log_probs = F.log_softmax(logits, dim=-1)\n",
    "    \n",
    "    sequence_prob = 0.0  # Start with 0 since we're adding logs\n",
    "    for i in range(input_ids.size(1)):\n",
    "        token_id = input_ids[0, i].item()\n",
    "        token_log_prob = log_probs[0, i, token_id].item()\n",
    "        sequence_prob += token_log_prob  # Add instead of multiply\n",
    "    \n",
    "    return sequence_prob/input_ids.size(1)  # This will be the avg log probability\n",
    "\n",
    "def generate_sequence(model, input_ids, vector, coeff, max_new_tokens):\n",
    "    model.reset()\n",
    "    model.set_control(coeff * vector)\n",
    "    settings = {\n",
    "        \"pad_token_id\": tokenizer.eos_token_id,\n",
    "        \"temperature\": 1e-6,\n",
    "        \"max_new_tokens\": max_new_tokens,\n",
    "        #\"repetition_penalty\": 1,\n",
    "    }\n",
    "    with torch.no_grad():  # <-- Add this line\n",
    "        output = model.generate(**input_ids, **settings)\n",
    "    return output[0]\n",
    "\n",
    "def calculate_perplexity_for_each_token(model, sequence):\n",
    "    model.reset()\n",
    "    perplexities = []\n",
    "    for i in range(1, len(sequence)+1):\n",
    "        #pplx = calculate_perplexity(model, sequence[0:i])\n",
    "        pplx = calculate_sequence_probability(model, sequence[0:i])\n",
    "        #pplx = calculate_adjusted_perplexity(pplx, current_text)\n",
    "        perplexities.append(pplx)\n",
    "    return perplexities\n",
    "\n",
    "def calculate_perplexities_over_sequence(model, tokenizer, input_text, vector, token_count, start_coeff=0.16, iterations=20, end_coeff=1.0):\n",
    "    coefficients = []\n",
    "    all_perplexities = []\n",
    "    outputs = []\n",
    "\n",
    "    coeff = start_coeff\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
    "    for _ in tqdm.tqdm(range(iterations), desc=\"Testing coefficients\"):\n",
    "        #print(coeff)\n",
    "        sequence = generate_sequence(model, input_ids, vector, coeff, token_count)\n",
    "        perplexities = calculate_perplexity_for_each_token(model, sequence)\n",
    "        \n",
    "        coefficients.append(coeff)\n",
    "        all_perplexities.append(perplexities)\n",
    "        output = tokenizer.decode(sequence, skip_special_tokens=True)\n",
    "        outputs.append(output)\n",
    "        \n",
    "        coeff += (end_coeff-start_coeff)/(iterations-1)\n",
    "    \n",
    "    return coefficients, all_perplexities, outputs\n",
    "\n",
    "TEMPLATE = \"\"\"{persona}. {prefill}\"\"\"\n",
    "\n",
    "def make_dataset(\n",
    "    persona_template: str,\n",
    "    positive_personas: list[str],\n",
    "    negative_personas: list[str],\n",
    "    user_msg: str,\n",
    "    suffix_list: list[str]\n",
    ") -> list[DatasetEntry]:\n",
    "    dataset = []\n",
    "    for suffix in suffix_list:\n",
    "        for positive_persona, negative_persona in zip(positive_personas, negative_personas):\n",
    "            pos = persona_template.format(persona=positive_persona)\n",
    "            neg = persona_template.format(persona=negative_persona)\n",
    "            dataset.append(\n",
    "                DatasetEntry(\n",
    "                    positive=TEMPLATE.format(persona=pos, user_msg=user_msg, prefill=suffix),\n",
    "                    negative=TEMPLATE.format(persona=neg, user_msg=user_msg, prefill=suffix),\n",
    "                )\n",
    "            )\n",
    "    return dataset\n",
    "\n",
    "# Create all widgets\n",
    "mode_toggle = widgets.ToggleButtons(\n",
    "    options=['Base Mode', 'Chat Mode'],\n",
    "    value='Base Mode'\n",
    ")\n",
    "\n",
    "steering_input = widgets.Textarea(\n",
    "    placeholder='Enter steering prompt...',\n",
    "    layout={'width': '100%'}\n",
    ")\n",
    "\n",
    "input_box = widgets.Textarea(\n",
    "    placeholder='Enter text...',\n",
    "    layout={'width': '100%'}\n",
    ")\n",
    "\n",
    "upper_bound = 2.0\n",
    "\n",
    "strength_slider = widgets.FloatSlider(\n",
    "    min=-1 * upper_bound, max=upper_bound, value=0.0,\n",
    "    description='Strength:',\n",
    "    step=0.01,\n",
    "    #Add marks at key points\n",
    "    # marks=[\n",
    "    #     (-1 * upper_bound, '-max'),\n",
    "    #     (upper_bound, 'max')\n",
    "    # ],\n",
    "    # Make marks visible\n",
    "    readout=True,\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "generate_button = widgets.Button(description='Generate')\n",
    "\n",
    "steering_generate_button = widgets.Button(description='Train Steering Vector')\n",
    "\n",
    "clear_history_button = widgets.Button(description='Clear History')\n",
    "\n",
    "status_display = widgets.HTML()\n",
    "output_display = widgets.Output()\n",
    "\n",
    "# Main container for chat history\n",
    "chat_display = widgets.HTML()\n",
    "chat_history = []\n",
    "\n",
    "steering_vector = None\n",
    "\n",
    "def on_generate_click(b):\n",
    "    if mode_toggle.value == 'Base Mode':\n",
    "        # Handle base mode generation\n",
    "        prompt = input_box.value.strip()\n",
    "        if not prompt:\n",
    "            status_display.value = 'Please enter text'\n",
    "            return\n",
    "        if not steering_vector:\n",
    "            status_display.value = 'Please generate a steering vector first'\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            status_display.value = f'Generating from base model with prompt \"{prompt}\" and coefficient {strength_slider.value:.2f}. Please wait...'\n",
    "            input_ids = tokenizer(prompt, return_tensors=\"pt\").to(base_model.device)\n",
    "            base_model.reset()\n",
    "            base_model.set_control(strength_slider.value * steering_vector)\n",
    "            settings = {\n",
    "                \"pad_token_id\": tokenizer.eos_token_id,\n",
    "                \"temperature\": 0.7,\n",
    "                \"max_new_tokens\": 128,\n",
    "                \"repetition_penalty\": 1.1,\n",
    "            }\n",
    "            with torch.no_grad():  # <-- Add this line\n",
    "                sequence = base_model.generate(**input_ids, **settings)[0]\n",
    "            output = tokenizer.decode(sequence, skip_special_tokens=True)\n",
    "            \n",
    "            status_display.value = textwrap.fill(output, width=80)\n",
    "                \n",
    "        except Exception as e:\n",
    "            status_display.value = f'Error: {str(e)}'\n",
    "            \n",
    "    else:\n",
    "        # Handle chat mode\n",
    "        message = input_box.value.strip()\n",
    "        if not message:\n",
    "            status_display.value = 'Please enter a message'\n",
    "            return\n",
    "            \n",
    "        # Add user message to history\n",
    "        chat_history.append(('user', message))\n",
    "        input_box.value = ''\n",
    "        \n",
    "        try:\n",
    "            status_display.value = f'Generating from instruct model with prompt \"{message}\" and coefficient {strength_slider.value:.2f}. Please wait...'\n",
    "            # Format the full chat history into a single prompt\n",
    "            chat_prompt = \"\"\n",
    "            \n",
    "            for entry in chat_history:\n",
    "                role, content = entry\n",
    "                if role == \"user\":\n",
    "                    chat_prompt += f\"<|start_header_id|>user<|end_header_id|>\\n{content}<|eot_id|>\\n\"\n",
    "                else:\n",
    "                    chat_prompt += f\"<|start_header_id|>assistant<|end_header_id|>\\n\\n{content}<|eot_id|>\\n\"\n",
    "            \n",
    "            chat_prompt += \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "\n",
    "            # Generate response using the same logic as base mode\n",
    "            input_ids = tokenizer(chat_prompt, return_tensors=\"pt\").to(instruct_model.device)\n",
    "            instruct_model.reset()\n",
    "            instruct_model.set_control(strength_slider.value * steering_vector)\n",
    "            \n",
    "            settings = {\n",
    "                \"pad_token_id\": tokenizer.eos_token_id,\n",
    "                \"temperature\": 0.7,\n",
    "                \"max_new_tokens\": 128,\n",
    "                \"repetition_penalty\": 1.1,\n",
    "            }\n",
    "            \n",
    "            with torch.no_grad():  # <-- Add this line\n",
    "                output = instruct_model.generate(\n",
    "                    **input_ids, \n",
    "                    **settings\n",
    "                )\n",
    "            response = tokenizer.decode(output[0])\n",
    "\n",
    "            # Split to get just the assistant's response\n",
    "            response = response.split(\"<|start_header_id|>assistant<|end_header_id|>\\n\\n\")[-1]\n",
    "\n",
    "            # No need to split on eot_id since it's at the end\n",
    "            response = response.strip()\n",
    "            if response.endswith(\"<|eot_id|>\"):\n",
    "                response = response[:-len(\"<|eot_id|>\")]\n",
    "\n",
    "            # Add response to chat history\n",
    "            chat_history.append(('assistant', response))\n",
    "            \n",
    "            # Update chat display\n",
    "            html = []\n",
    "            for role, content in chat_history:\n",
    "                color = \"blue\" if role == \"user\" else \"green\"\n",
    "                html.append(f'<div style=\"color: {color}\"><b>{role}:</b> {content}</div>')\n",
    "            chat_display.value = '<br>'.join(html)\n",
    "\n",
    "            status_display.value = \"\"\n",
    "\n",
    "        except Exception as e:\n",
    "            status_display.value = f'Error: {str(e)}'\n",
    "            # You can access chat_history for context\n",
    "            chat_history.pop()\n",
    "            \n",
    "            # Update chat display\n",
    "            html = []\n",
    "            for role, content in chat_history:\n",
    "                color = \"blue\" if role == \"user\" else \"green\"\n",
    "                html.append(f'<div style=\"color: {color}\"><b>{role}:</b> {content}</div>')\n",
    "            chat_display.value = '<br>'.join(html)\n",
    "            \n",
    "\n",
    "def on_mode_change(change):\n",
    "    if change['new'] == 'Base Mode':\n",
    "        chat_display.layout.display = 'none'\n",
    "        output_display.layout.display = 'block'\n",
    "    else:\n",
    "        chat_display.layout.display = 'block'\n",
    "        output_display.layout.display = 'none'\n",
    "    input_box.value = ''\n",
    "    status_display.value = ''\n",
    "\n",
    "def on_steering_generate_click(b):\n",
    "    #setattr(status_display, 'value', 'Steering vector generated!')\n",
    "    steering_prompt = steering_input.value.strip()\n",
    "    if not steering_prompt:\n",
    "        status_display.value = 'Please enter steering prompt'\n",
    "        return\n",
    "    \n",
    "    steering_dataset = make_dataset(\n",
    "        \"{persona}\",\n",
    "        [steering_prompt],\n",
    "        [\"an AI\"],\n",
    "        \"\",\n",
    "        truncated_output_suffixes,\n",
    "    )\n",
    "\n",
    "    status_display.value = f'Made dataset for prompt \"{steering_prompt}\", now training...'\n",
    "\n",
    "    base_model.reset()\n",
    "    global steering_vector\n",
    "    steering_vector = ControlVector.train_with_sae(\n",
    "        base_model,\n",
    "        tokenizer,\n",
    "        sae,\n",
    "        steering_dataset,\n",
    "        batch_size=32,\n",
    "        method=\"pca_center\",\n",
    "        hidden_layers=control_layers\n",
    "    )\n",
    "\n",
    "    status_display.value = 'Trained, now calculating maximum steering coefficient...'\n",
    "\n",
    "    input_text = \"I am\"\n",
    "    token_count = 24\n",
    "\n",
    "    #print(f\"Calculating for {token_count} tokens...\")\n",
    "    coefficients, all_perplexities, _ = calculate_perplexities_over_sequence(base_model, tokenizer, input_text, steering_vector, token_count, start_coeff=0., iterations=10, end_coeff=1.0)\n",
    "    x = np.array(coefficients)\n",
    "    perplexities = [pplx[-1] for pplx in all_perplexities]\n",
    "    normalized_perplexities = [pplx / perplexities[0] for pplx in perplexities]\n",
    "    y = np.array(normalized_perplexities)\n",
    "\n",
    "    upper_bound_idx = find_significant_drop(x, y)\n",
    "    global upper_bound\n",
    "    if upper_bound_idx:\n",
    "        upper_bound = coefficients[upper_bound_idx-1]\n",
    "    else:\n",
    "        upper_bound = 1.0\n",
    "        upper_bound_idx = len(coefficients)-1\n",
    "    # After calculating the new upper_bound\n",
    "    strength_slider.min = -1 * upper_bound\n",
    "    strength_slider.max = upper_bound\n",
    "    # Optionally reset value to 0 or clamp to new range\n",
    "    strength_slider.value = max(min(strength_slider.value, upper_bound), -1 * upper_bound)\n",
    "\n",
    "    status_display.value = 'Recommended min/max coefficients are -{} and {}. Ready to steer!'.format(upper_bound, upper_bound)\n",
    "\n",
    "    visualize_discontinuities(x, y, [upper_bound_idx])\n",
    "\n",
    "def on_clear_history(b):\n",
    "    global chat_history\n",
    "    chat_history = []\n",
    "    chat_display.value = \"\"\n",
    "    status_display.value = \"\"\n",
    "\n",
    "def on_mode_change(change):\n",
    "    if change['new'] == 'Base Mode':\n",
    "        chat_display.layout.display = 'none'\n",
    "        clear_history_button.layout.display = 'none'  # Hide clear button in base mode\n",
    "        output_display.layout.display = 'block'\n",
    "    else:\n",
    "        chat_display.layout.display = 'block'\n",
    "        clear_history_button.layout.display = 'block'  # Show clear button in chat mode\n",
    "        output_display.layout.display = 'none'\n",
    "    input_box.value = ''\n",
    "    status_display.value = ''\n",
    "\n",
    "# Wire up callbacks\n",
    "generate_button.on_click(on_generate_click)\n",
    "steering_generate_button.on_click(on_steering_generate_click)\n",
    "mode_toggle.observe(on_mode_change, names='value')\n",
    "clear_history_button.on_click(on_clear_history)\n",
    "\n",
    "# Create and display interface\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Text Generation Demo</h3>\"),\n",
    "    mode_toggle,\n",
    "    steering_input,\n",
    "    steering_generate_button,\n",
    "    input_box,\n",
    "    strength_slider,\n",
    "    generate_button,\n",
    "    clear_history_button,\n",
    "    status_display,\n",
    "    output_display,\n",
    "    chat_display\n",
    "]))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
